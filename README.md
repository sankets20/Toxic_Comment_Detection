# Toxic_Comment_Detection
Introduction:

This project is a Natural Language Processing (NLP) endeavor aimed at automatically classifying text comments into "toxic" or "not toxic" categories. Leveraging machine learning techniques, specifically the Multinomial Naive Bayes classifier and TF-IDF vectorization, the system learns to distinguish toxic comments from non-toxic ones. It's a valuable tool for content moderation, sentiment analysis, and online community management.

Key Features:

Data Preprocessing: The project includes data cleaning and preprocessing steps, such as handling missing values, converting labels to binary format, and eliminating duplicate data.

Model Training: A Multinomial Naive Bayes classifier is used for training the toxic comment classification model. This model is known for its effectiveness in text classification tasks.

TF-IDF Vectorization: Comments are transformed into numerical vectors using the TF-IDF (Term Frequency-Inverse Document Frequency) vectorization technique. This allows the model to work with textual data effectively.

Evaluation: The model's performance is assessed using metrics like accuracy and a classification report, providing insights into precision, recall, and F1-score.

Usage:

To use this project:

Clone the repository to your local machine.
Install the required Python libraries listed in the README.
Follow the instructions in the README to train the classifier on your dataset and make predictions.

Example Comments:

The project comes with example comments that showcase the model's ability to classify text into "toxic" or "not toxic" categories. It provides a practical demonstration of how the model works.
#Dataset:https://drive.google.com/file/d/1hPdf3MUVD-aeaosOAaYxtiisqXpB24Pa/view?usp=sharing
